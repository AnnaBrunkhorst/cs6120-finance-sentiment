{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f30f5b-0b5a-48bc-996f-1279d41cf352",
   "metadata": {},
   "source": [
    "## Sentiment Analysis in Finance\n",
    "\n",
    "### Logistic Regression Classification Model: Alpha Vantage Dataset\n",
    "\n",
    "##### Team 103: Anna Brunkhorst, Nader Lobandi, Ashish Magadum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd95dcea-f9f5-43b9-947b-9fcbd24f15bc",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfc04ef-462c-4db4-886d-42f6530fc72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abrun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38864e8-eed7-4226-a27c-bf6c9ca7a7d8",
   "metadata": {},
   "source": [
    "Check for necessary folders & files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0e4aae-d272-48a4-a2c9-151f31268909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary data files found in ./data.\n",
      "./models folder found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# List of required files in the ./data directory\n",
    "required_files = [\n",
    "    './data/alpha_vantage_train.csv',\n",
    "    './data/alpha_vantage_test.csv',\n",
    "    './data/glove.6B.100d.txt'\n",
    "]\n",
    "\n",
    "# Check if the ./data directory exists\n",
    "if not os.path.exists('./data'):\n",
    "    print(\"STOP: ./data folder missing from this directory.\")\n",
    "    sys.exit(1)  # Stop the notebook from running any further\n",
    "\n",
    "# Check for each required file in the list\n",
    "missing_files = False\n",
    "for file_path in required_files:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"STOP: {os.path.basename(file_path)} data file missing from ./data folder.\")\n",
    "        missing_files = True\n",
    "\n",
    "if missing_files:\n",
    "    sys.exit(1)  # Exit if any file is missing\n",
    "\n",
    "print(\"Necessary data files found in ./data.\")\n",
    "\n",
    "# Check if the ./models directory exists, and create it if it does not\n",
    "models_path = './models'\n",
    "if not os.path.exists(models_path):\n",
    "    os.makedirs(models_path)\n",
    "    print(\"./models folder created!\")\n",
    "else:\n",
    "    print(\"./models folder found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49486e-f84f-4e14-b48f-faf9af0b5e29",
   "metadata": {},
   "source": [
    "Define data preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb9b4a6c-d0af-46ad-aece-b5ed04a86d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "    \n",
    "    def cleaning(doc):\n",
    "        txt = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "        return ' '.join(txt)\n",
    "    \n",
    "    brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in data['text'])\n",
    "    cleaned_txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=2500, n_process=-1)]\n",
    "    data['cleaned_text'] = cleaned_txt\n",
    "    \n",
    "    return data[['cleaned_text', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1473d2-f328-4a9c-aa4f-9672ca095052",
   "metadata": {},
   "source": [
    "Preprocess and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec242ff-223c-47a9-beaf-67ac36e07531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data preprocessed!\n",
      "Testing data preprocessed!\n",
      "Preprocessed data saved.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training and testing data separately\n",
    "train_data_processed = preprocess_data('./data/alpha_vantage_train.csv')\n",
    "print(\"Training data preprocessed!\")\n",
    "test_data_processed = preprocess_data('./data/alpha_vantage_test.csv')\n",
    "print(\"Testing data preprocessed!\")\n",
    "\n",
    "# Save preprocessed data to new CSV files\n",
    "train_data_processed.to_csv('./data/alpha_vantage_train_processed.csv', index=False)\n",
    "test_data_processed.to_csv('./data/alpha_vantage_test_processed.csv', index=False)\n",
    "print(\"Preprocessed data saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae816de0-1fe7-4a21-9a4a-3f8f63ec6804",
   "metadata": {},
   "source": [
    "Function to load GLoVe model from file of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d6d515-cef0-49c7-99c3-a77890afe5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file):\n",
    "    with open(glove_file, 'r', encoding='utf8') as f:\n",
    "        model = {}\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            model[word] = embedding\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1ad89-c541-47a0-a2d3-c60dbec333bb",
   "metadata": {},
   "source": [
    "Function to process a text document to produce a single vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a85b7a7-aeb5-40f8-975c-b6afd421abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc, glove_model):\n",
    "    words = doc.split()\n",
    "    word_vectors = [glove_model.get(word, np.zeros(100)) for word in words]\n",
    "    vector = np.mean(word_vectors, axis=0) if word_vectors else np.zeros(100)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080bebcb-e005-43f5-9353-29b7db11e2b2",
   "metadata": {},
   "source": [
    "Function to load and vectorize data from a given file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1219fd-c7f3-4300-a5b3-1296af94720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_vectorize_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['doc_vector'] = data['cleaned_text'].apply(lambda doc: document_vector(doc, glove_model))\n",
    "    X = np.array(data['doc_vector'].tolist())\n",
    "    y = data['label'].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603a0f7-00ec-4970-86ff-5278b8709165",
   "metadata": {},
   "source": [
    "Loading in GLoVe model and train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbadcaf6-8647-426f-b849-3760ba2efa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = load_glove_model('./data/glove.6B.100d.txt')\n",
    "\n",
    "X_train, y_train = load_and_vectorize_data('./data/alpha_vantage_train_processed.csv')\n",
    "X_test, y_test = load_and_vectorize_data('./data/alpha_vantage_test_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53676da-7916-44e7-8359-2acca41886ef",
   "metadata": {},
   "source": [
    "Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd7c9b46-8aae-4afd-bf63-d6f78c86f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45201731-ed4b-446f-b349-5d03f2850aaf",
   "metadata": {},
   "source": [
    "Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4958418-014c-4c7f-ad3b-a47ac36635bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.02        94\n",
      "           1       0.57      0.35      0.44      1089\n",
      "           2       0.55      0.66      0.60      3004\n",
      "           3       0.58      0.63      0.60      2492\n",
      "           4       0.54      0.19      0.28       473\n",
      "\n",
      "    accuracy                           0.56      7152\n",
      "   macro avg       0.51      0.37      0.39      7152\n",
      "weighted avg       0.56      0.56      0.55      7152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9f9bc0-65f7-4177-b40e-0dd4e659fc20",
   "metadata": {},
   "source": [
    "Save report and model in ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248095bd-3e26-4f50-9100-dc806a082476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/alpha_vantage_log_reg.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report.to_csv('./models/alpha_vantage_log_reg_report.csv', index=True)\n",
    "\n",
    "joblib.dump(model, './models/alpha_vantage_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03460d51-02ec-489d-ad67-25e4567dbc96",
   "metadata": {},
   "source": [
    "### Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc273498-e00e-4c66-92b4-5547da7bc995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_document_vector (__main__.TestSentimentAnalysis.test_document_vector)\n",
      "Test the document vector function produces correct output ... ok\n",
      "test_load_glove_model (__main__.TestSentimentAnalysis.test_load_glove_model)\n",
      "Test that the GloVe model loads correctly and vector dimensions are right ... ok\n",
      "test_preprocess_data (__main__.TestSentimentAnalysis.test_preprocess_data)\n",
      "Test the preprocessing function to ensure it outputs the expected format ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 33.875s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x15718c8e7e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import os\n",
    "\n",
    "class TestSentimentAnalysis(unittest.TestCase):\n",
    "    \n",
    "    def test_preprocess_data(self):\n",
    "        \"\"\" Test the preprocessing function to ensure it outputs the expected format \"\"\"\n",
    "        sample_data = pd.DataFrame({\n",
    "            'text': ['This is a sample!'],\n",
    "            'label': [1]\n",
    "        })\n",
    "        sample_data.to_csv('sample_data.csv', index=False)\n",
    "        \n",
    "        processed_data = preprocess_data('sample_data.csv')\n",
    "        os.remove('sample_data.csv')  # Clean up the sample file\n",
    "        \n",
    "        self.assertIn('cleaned_text', processed_data.columns)\n",
    "        self.assertIn('label', processed_data.columns)\n",
    "        self.assertEqual(processed_data['label'].iloc[0], 1)\n",
    "        self.assertEqual(type(processed_data['cleaned_text'].iloc[0]), str)\n",
    "\n",
    "    def test_load_glove_model(self):\n",
    "        \"\"\" Test that the GloVe model loads correctly and vector dimensions are right \"\"\"\n",
    "        glove_sample = './data/glove_sample.txt'\n",
    "        with open(glove_sample, 'w') as f:\n",
    "            f.write('hello 0.1 0.2 0.3 0.4\\nworld 0.5 0.6 0.7 0.8\\n')\n",
    "        \n",
    "        glove = load_glove_model(glove_sample)\n",
    "        os.remove(glove_sample)  # Clean up the sample file\n",
    "        \n",
    "        self.assertIn('hello', glove)\n",
    "        self.assertIn('world', glove)\n",
    "        self.assertEqual(len(glove['hello']), 4)\n",
    "        self.assertTrue(np.array_equal(glove['hello'], np.array([0.1, 0.2, 0.3, 0.4])))\n",
    "\n",
    "    def test_document_vector(self):\n",
    "        \"\"\" Test the document vector function produces correct output \"\"\"\n",
    "        glove_sample = {'test': np.array([1, 1, 1, 1])}\n",
    "        doc = 'test test test'\n",
    "        result_vector = document_vector(doc, glove_sample)\n",
    "        \n",
    "        self.assertEqual(result_vector.shape[0], 4)\n",
    "        self.assertTrue(np.array_equal(result_vector, np.array([1, 1, 1, 1])))\n",
    "\n",
    "# Run the tests\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
